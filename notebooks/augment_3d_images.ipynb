{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mask_dir = \"../assets/wm_gm_csf_masks\"\n",
    "source_data_dir = \"../assets/source_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 359)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(source_data_dir)), len(os.listdir(source_mask_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_source_dir = \"../assets/augmented_source_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_data_dir = \"../assets/cc_motion_corrupted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(augmented_source_dir, exist_ok=True)\n",
    "os.makedirs(destination_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_transformation = tio.transforms.RandomMotion(\n",
    "    degrees=5,\n",
    "    translation=10,\n",
    "    num_transforms=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = (256, 288, 288)\n",
    "\n",
    "crop_or_pad = tio.CropOrPad(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_images = os.listdir(source_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(image, mask):\n",
    "    image_array = image.get_fdata()\n",
    "    mask_array = mask.get_fdata()\n",
    "\n",
    "    mask_array = mask_array.astype(bool)\n",
    "\n",
    "    masked_image_array = image_array * mask_array\n",
    "\n",
    "    masked_image = nib.Nifti1Image(masked_image_array, image.affine)\n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_contrast_inversion(image, mask):\n",
    "  image_array = image.get_fdata()\n",
    "  mask_array = mask.get_fdata()\n",
    "      \n",
    "  threshold = np.max(mask_array)\n",
    "\n",
    "  binary_mask = mask_array == threshold\n",
    "\n",
    "  max_intensity = np.max(image_array[binary_mask])\n",
    "\n",
    "  inversed_image_array = image_array.copy()\n",
    "  inversed_image_array[binary_mask] = max_intensity - image_array[binary_mask]\n",
    "\n",
    "  print(inversed_image_array[:, :, 170][40, 150])\n",
    "\n",
    "  inversed_image = nib.Nifti1Image(inversed_image_array, image.affine)\n",
    "\n",
    "  return inversed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/359 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing: CC0001_philips_15_55_M.nii\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/359 [00:02<16:12,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.715911626815796\n",
      "Now processing: CC0002_philips_15_56_M.nii\n",
      "878.4688711166382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/359 [00:04<14:26,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2225780487060547\n",
      "Now processing: CC0003_philips_15_63_F.nii\n",
      "373.68133068084717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/359 [00:07<13:59,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2766199111938477\n",
      "Now processing: CC0004_philips_15_67_M.nii\n",
      "346.6593360900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/359 [00:09<13:12,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.0375139713287354\n",
      "Now processing: CC0005_philips_15_62_M.nii\n",
      "816.4307956695557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/359 [00:11<13:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1728880405426025\n",
      "Now processing: CC0006_philips_15_63_F.nii\n",
      "789.6581172943115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/359 [00:13<12:57,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1885125637054443\n",
      "Now processing: CC0007_philips_15_62_M.nii\n",
      "1004.6986770629883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/359 [00:15<12:53,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.182027578353882\n",
      "Now processing: CC0008_philips_15_60_F.nii\n",
      "940.5949058532715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/359 [00:17<12:35,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.0546305179595947\n",
      "Now processing: CC0009_philips_15_69_M.nii\n",
      "292.3252716064453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/359 [00:19<12:19,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.0302956104278564\n",
      "Now processing: CC0010_philips_15_69_F.nii\n",
      "721.129150390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/359 [00:22<12:22,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.152216911315918\n",
      "Now processing: CC0011_philips_15_49_F.nii\n",
      "476.36754512786865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/359 [00:24<13:22,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.715491771697998\n",
      "Now processing: CC0012_philips_15_43_M.nii\n",
      "369.36579513549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/359 [00:27<14:54,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.1910948753356934\n",
      "Now processing: CC0013_philips_15_66_M.nii\n",
      "987.5897598266602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 13/359 [00:30<15:37,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.015559434890747\n",
      "Now processing: CC0014_philips_15_62_F.nii\n",
      "431.9286880493164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/359 [00:33<14:56,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.3412532806396484\n",
      "Now processing: CC0015_philips_15_44_M.nii\n",
      "852.911376953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 15/359 [00:35<14:21,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2874386310577393\n",
      "Now processing: CC0016_philips_15_55_M.nii\n",
      "754.1916751861572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 16/359 [00:37<13:45,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.177082061767578\n",
      "Now processing: CC0017_philips_15_50_F.nii\n",
      "838.6735229492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/359 [00:39<13:14,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.124025583267212\n",
      "Now processing: CC0018_philips_15_41_F.nii\n",
      "293.7308921813965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 18/359 [00:42<12:58,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1873619556427\n",
      "Now processing: CC0019_philips_15_57_F.nii\n",
      "771.0632553100586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 19/359 [00:44<12:37,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1031911373138428\n",
      "Now processing: CC0020_philips_15_65_F.nii\n",
      "458.9323425292969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 20/359 [00:46<12:42,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2969038486480713\n",
      "Now processing: CC0021_philips_15_48_F.nii\n",
      "391.765585899353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 21/359 [00:48<12:30,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.148927688598633\n",
      "Now processing: CC0022_philips_15_43_M.nii\n",
      "709.4017105102539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 22/359 [00:50<12:23,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1737356185913086\n",
      "Now processing: CC0023_philips_15_43_M.nii\n",
      "1012.2144012451172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 23/359 [00:52<12:16,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1625418663024902\n",
      "Now processing: CC0024_philips_15_65_F.nii\n",
      "918.8024291992188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 24/359 [00:55<12:05,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1039788722991943\n",
      "Now processing: CC0025_philips_15_51_M.nii\n",
      "318.80342960357666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 25/359 [00:57<12:27,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.4019360542297363\n",
      "Now processing: CC0026_philips_15_65_M.nii\n",
      "816.811689376831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 26/359 [00:59<12:16,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.1464407444000244\n",
      "Now processing: CC0027_philips_15_41_M.nii\n",
      "456.5384531021118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 27/359 [01:01<12:14,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2102813720703125\n",
      "Now processing: CC0028_philips_15_63_F.nii\n",
      "562.6461496353149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 28/359 [01:04<12:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.173082113265991\n",
      "Now processing: CC0029_philips_15_51_M.nii\n",
      "547.7020645141602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 29/359 [01:06<12:48,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.6325037479400635\n",
      "Now processing: CC0030_philips_15_42_F.nii\n",
      "540.1289100646973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30/359 [01:09<12:55,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.4232892990112305\n",
      "Now processing: CC0031_philips_15_65_F.nii\n",
      "935.7369623184204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 31/359 [01:11<12:33,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.15461802482605\n",
      "Now processing: CC0032_philips_15_44_M.nii\n",
      "1066.910924911499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 32/359 [01:13<12:30,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.292771100997925\n",
      "Now processing: CC0033_philips_15_67_M.nii\n",
      "409.9203796386719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 33/359 [01:15<12:24,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.250732898712158\n",
      "Now processing: CC0034_philips_15_43_F.nii\n",
      "262.12502670288086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 34/359 [01:18<12:17,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2346675395965576\n",
      "Now processing: CC0035_philips_15_49_F.nii\n",
      "525.2454376220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 35/359 [01:20<12:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.15708327293396\n",
      "Now processing: CC0036_philips_15_49_F.nii\n",
      "693.4307699203491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 36/359 [01:22<12:02,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.239257574081421\n",
      "Now processing: CC0037_philips_15_41_M.nii\n",
      "546.5384769439697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 37/359 [01:24<12:23,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.472599506378174\n",
      "Now processing: CC0038_philips_15_41_F.nii\n",
      "392.0205240249634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 38/359 [01:27<12:16,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2598886489868164\n",
      "Now processing: CC0039_philips_15_41_F.nii\n",
      "552.6417694091797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 39/359 [01:29<12:58,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.756859302520752\n",
      "Now processing: CC0040_philips_15_55_F.nii\n",
      "425.47863006591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 40/359 [01:32<12:43,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.296354055404663\n",
      "Now processing: CC0041_philips_15_61_F.nii\n",
      "329.86664390563965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 41/359 [01:34<12:49,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.484147310256958\n",
      "Now processing: CC0042_philips_15_67_M.nii\n",
      "745.5555963516235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 42/359 [01:36<12:33,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.2737467288970947\n",
      "Now processing: CC0043_philips_15_58_F.nii\n",
      "492.87179470062256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 43/359 [01:39<12:34,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.408194065093994\n",
      "Now processing: CC0044_philips_15_36_M.nii\n",
      "894.5306234359741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 44/359 [01:41<12:45,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.5343544483184814\n",
      "Now processing: CC0045_philips_15_49_F.nii\n",
      "364.23954677581787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 45/359 [01:44<12:54,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.5492806434631348\n",
      "Now processing: CC0046_philips_15_42_M.nii\n",
      "873.3650636672974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 46/359 [01:47<13:23,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.805335521697998\n",
      "Now processing: CC0047_philips_15_54_F.nii\n",
      "751.3494057655334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 47/359 [01:50<14:09,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.075718879699707\n",
      "Now processing: CC0048_philips_15_53_M.nii\n",
      "695.5311298370361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 48/359 [01:52<13:29,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.322282552719116\n",
      "Now processing: CC0049_philips_15_43_F.nii\n",
      "1061.032512664795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 49/359 [01:55<14:08,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.056157112121582\n",
      "Now processing: CC0050_philips_15_45_M.nii\n",
      "694.8500986099243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 50/359 [01:58<13:52,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.5892531871795654\n",
      "Now processing: CC0051_philips_15_44_F.nii\n",
      "887.8857383728027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 51/359 [02:00<13:15,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.326901912689209\n",
      "Now processing: CC0052_philips_15_51_M.nii\n",
      "853.7669906616211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 52/359 [02:03<13:35,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.824083089828491\n",
      "Now processing: CC0053_philips_15_39_F.nii\n",
      "899.098388671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 53/359 [02:05<13:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.4255263805389404\n",
      "Now processing: CC0054_philips_15_46_M.nii\n",
      "838.8493480682373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 53/359 [02:07<12:13,  2.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m three_d_image \u001b[38;5;241m=\u001b[39m apply_contrast_inversion(three_d_image, image_mask)\n\u001b[0;32m     19\u001b[0m three_d_image \u001b[38;5;241m=\u001b[39m crop_or_pad(three_d_image)\n\u001b[1;32m---> 21\u001b[0m transformed_image \u001b[38;5;241m=\u001b[39m \u001b[43mmotion_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthree_d_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m nib\u001b[38;5;241m.\u001b[39msave(three_d_image, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(augmented_source_dir, image))\n\u001b[0;32m     23\u001b[0m nib\u001b[38;5;241m.\u001b[39msave(transformed_image, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_data_dir, image))\n",
      "File \u001b[1;32mc:\\Work\\Study\\Semester 1\\ENSF 619\\Final Project\\tiny_brains\\venv\\Lib\\site-packages\\torchio\\transforms\\transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Work\\Study\\Semester 1\\ENSF 619\\Final Project\\tiny_brains\\venv\\Lib\\site-packages\\torchio\\transforms\\augmentation\\intensity\\random_motion.py:90\u001b[0m, in \u001b[0;36mRandomMotion.apply_transform\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m     88\u001b[0m     arguments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_interpolation\u001b[39m\u001b[38;5;124m'\u001b[39m][name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_interpolation\n\u001b[0;32m     89\u001b[0m transform \u001b[38;5;241m=\u001b[39m Motion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_include_exclude(arguments))\n\u001b[1;32m---> 90\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transformed, Subject)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed\n",
      "File \u001b[1;32mc:\\Work\\Study\\Semester 1\\ENSF 619\\Final Project\\tiny_brains\\venv\\Lib\\site-packages\\torchio\\transforms\\transform.py:165\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    163\u001b[0m     subject \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(subject)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 165\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m images_to_keep\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Work\\Study\\Semester 1\\ENSF 619\\Final Project\\tiny_brains\\venv\\Lib\\site-packages\\torchio\\transforms\\augmentation\\intensity\\random_motion.py:195\u001b[0m, in \u001b[0;36mMotion.apply_transform\u001b[1;34m(self, subject)\u001b[0m\n\u001b[0;32m    189\u001b[0m     transforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rigid_transforms(\n\u001b[0;32m    190\u001b[0m         np\u001b[38;5;241m.\u001b[39masarray(degrees),\n\u001b[0;32m    191\u001b[0m         np\u001b[38;5;241m.\u001b[39masarray(translation),\n\u001b[0;32m    192\u001b[0m         sitk_image,\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_interpolation, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m     transformed_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43msitk_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_interpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     result_arrays\u001b[38;5;241m.\u001b[39mappend(transformed_channel)\n\u001b[0;32m    202\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(result_arrays)\n",
      "File \u001b[1;32mc:\\Work\\Study\\Semester 1\\ENSF 619\\Final Project\\tiny_brains\\venv\\Lib\\site-packages\\torchio\\transforms\\augmentation\\intensity\\random_motion.py:286\u001b[0m, in \u001b[0;36mMotion.add_artifact\u001b[1;34m(self, image, transforms, times, interpolation)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m    285\u001b[0m     array \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mGetArrayFromImage(image)\u001b[38;5;241m.\u001b[39mtranspose()  \u001b[38;5;66;03m# sitk to np\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     spectrum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfourier_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     spectra\u001b[38;5;241m.\u001b[39mappend(spectrum)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_spectra(spectra, times)\n",
      "File \u001b[1;32mc:\\Work\\Study\\Semester 1\\ENSF 619\\Final Project\\tiny_brains\\venv\\Lib\\site-packages\\torchio\\transforms\\fourier.py:12\u001b[0m, in \u001b[0;36mFourierTransform.fourier_transform\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfftn(tensor)\n\u001b[1;32m---> 12\u001b[0m     fshift \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfftshift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fshift\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for image in tqdm(source_images, total=len(source_images)):\n",
    "    print(f\"Now processing: {image}\")\n",
    "\n",
    "    if image == \".DS_Store\":\n",
    "        continue\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    three_d_image = nib.load(os.path.join(source_data_dir, image))\n",
    "    image_mask = nib.load(os.path.join(source_mask_dir, image.split(\".\")[0] + \".nii\"))\n",
    "\n",
    "    three_d_image = apply_mask(three_d_image, image_mask)\n",
    "\n",
    "    three_d_image = apply_contrast_inversion(three_d_image, image_mask)\n",
    "\n",
    "    three_d_image = crop_or_pad(three_d_image)\n",
    "\n",
    "    transformed_image = motion_transformation(three_d_image)\n",
    "    nib.save(three_d_image, os.path.join(augmented_source_dir, image))\n",
    "    nib.save(transformed_image, os.path.join(destination_data_dir, image))\n",
    "\n",
    "    print(f\"Time taken: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 288, 288)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nib.load(destination_data_dir + \"/\" +os.listdir(augmented_source_dir)[120]).get_fdata().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
